



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.0.1">
    
    
      
        <title>Replication from local to Event Streams - Data Replication in context of Kafka and Event Streams</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.982221ab.css">
      
      
    
    
      <script src="../assets/javascripts/modernizr.1f0bcf2b.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../extra.css">
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#from-local-cluster-to-event-streams" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="Data Replication in context of Kafka and Event Streams" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Data Replication in context of Kafka and Event Streams
            </span>
            <span class="md-header-nav__topic">
              Replication from local to Event Streams
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/jbcodeforce/kp-data-replication.git/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="Data Replication in context of Kafka and Event Streams" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Data Replication in context of Kafka and Event Streams
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/jbcodeforce/kp-data-replication.git/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Introduction" class="md-nav__link">
      Introduction
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Mirror Maker 2.0
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Mirror Maker 2.0
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Replication from local to Event Streams
      </label>
    
    <a href="./" title="Replication from local to Event Streams" class="md-nav__link md-nav__link--active">
      Replication from local to Event Streams
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-requisites" title="Pre-requisites" class="md-nav__link">
    Pre-requisites
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-1-from-kafka-local-as-source-to-event-streams-on-cloud-as-target" title="Scenario 1: From Kafka local as source to Event Streams on Cloud as Target" class="md-nav__link">
    Scenario 1: From Kafka local as source to Event Streams on Cloud as Target
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-2-run-mirror-maker-2-cluster-close-to-target-cluster" title="Scenario 2: Run Mirror Maker 2 Cluster close to target cluster" class="md-nav__link">
    Scenario 2: Run Mirror Maker 2 Cluster close to target cluster
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deploy-mirror-maker-as-a-custom-image" title="Deploy Mirror Maker as a custom image" class="md-nav__link">
    Deploy Mirror Maker as a custom image
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-with-strimzi-mirror-maker-20-operator" title="Deploy with Strimzi Mirror Maker 2.0 Operator" class="md-nav__link">
    Deploy with Strimzi Mirror Maker 2.0 Operator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validate-data-replication" title="Validate data replication" class="md-nav__link">
    Validate data replication
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../es-to-local/" title="Replication from Event Streams to local" class="md-nav__link">
      Replication from Event Streams to local
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../provisioning/" title="Connector Provisioning" class="md-nav__link">
      Connector Provisioning
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/connect" title="Kafka Connect" class="md-nav__link">
      Kafka Connect
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Apache Kafka practices
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Apache Kafka practices
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/readme" title="Summary" class="md-nav__link">
      Summary
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/consumers" title="Consumer practices" class="md-nav__link">
      Consumer practices
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/producers" title="Producer practices" class="md-nav__link">
      Producer practices
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../monitoring/" title="Monitoring with Prometheus and Grafana" class="md-nav__link">
      Monitoring with Prometheus and Grafana
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-requisites" title="Pre-requisites" class="md-nav__link">
    Pre-requisites
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-1-from-kafka-local-as-source-to-event-streams-on-cloud-as-target" title="Scenario 1: From Kafka local as source to Event Streams on Cloud as Target" class="md-nav__link">
    Scenario 1: From Kafka local as source to Event Streams on Cloud as Target
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-2-run-mirror-maker-2-cluster-close-to-target-cluster" title="Scenario 2: Run Mirror Maker 2 Cluster close to target cluster" class="md-nav__link">
    Scenario 2: Run Mirror Maker 2 Cluster close to target cluster
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deploy-mirror-maker-as-a-custom-image" title="Deploy Mirror Maker as a custom image" class="md-nav__link">
    Deploy Mirror Maker as a custom image
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-with-strimzi-mirror-maker-20-operator" title="Deploy with Strimzi Mirror Maker 2.0 Operator" class="md-nav__link">
    Deploy with Strimzi Mirror Maker 2.0 Operator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validate-data-replication" title="Validate data replication" class="md-nav__link">
    Validate data replication
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/jbcodeforce/kp-data-replication.git/edit/master/docs/local-to-es.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="from-local-cluster-to-event-streams">From Local cluster to Event Streams</h1>
<p>We propose two approaches to run the 'local' cluster:</p>
<ul>
<li><a href="#scenario-1-from-kafka-local-as-source-to-event-streams-on-cloud-as-target">Docker compose vanilla Kafka 2.4</a>: To run local cluster we use docker-compose and docker. The docker compose file to start a local 3 Kafka brokers and 2 Zookeepers cluster is in <code>mirror-maker-2/local-cluster</code> folder. This compose file uses a local docker network called <code>kafkanet</code>. The docker image used for Kafka is coming from Strimzi open source project and is for the Kafka 2.4 version.</li>
<li><a href="#scenario-2-run-mirror-maker-2-cluster-close-to-target-cluster">Openshift deployed Kafka 2.4 cluster using Strimzi operator</a></li>
</ul>
<h2 id="pre-requisites">Pre-requisites</h2>
<ul>
<li>You need to have one Event Streams service created on IBM Cloud.</li>
<li>You may need to use Event Streams CLI. So follow <a href="https://cloud.ibm.com/docs/services/EventStreams?topic=eventstreams-cli#cli">those instructions</a> to get it.</li>
</ul>
<p>The following ibmcloud CLI command presents the Event Stream cluster's metadata, like the broker list and the cluster ID:</p>
<div class="codehilite"><pre><span></span>ibmcloud es cluster
</pre></div>

<p>For other CLI commands see <a href="https://cloud.ibm.com/docs/services/EventStreams?topic=eventstreams-cli_reference">this summary</a>.</p>
<h2 id="scenario-1-from-kafka-local-as-source-to-event-streams-on-cloud-as-target">Scenario 1: From Kafka local as source to Event Streams on Cloud as Target</h2>
<p>The test scenario goal is to send the product definitions in the local <code>products</code> topic and then start mirror maker to see the data replicated to the <code>source.products</code> topic in Event Streams cluster.</p>
<p><img alt="Local Kafka to Event Streams" src="../images/local-to-es.png" /></p>
<ul>
<li>Set the environment variables in <code>setenv.sh</code> script for the source broker to be your local cluster, and the target to be event streams. Be sure to also set Event Streams APIKEY:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="nb">export</span> <span class="nv">KAFKA_SOURCE_BROKERS</span><span class="o">=</span>kafka1:9092,kafka2:9093,kafka3:9094

<span class="nb">export</span> <span class="nv">KAFKA_TARGET_BROKERS</span><span class="o">=</span>broker-3-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-5-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093
<span class="nb">export</span> <span class="nv">KAFKA_TARGET_APIKEY</span><span class="o">=</span><span class="s2">&quot;&lt;password attribut in event streams credentials&gt;&quot;</span>
</pre></div>

<ul>
<li>It may be needed to create the topics in the target cluster. This depends if mirror maker 2.0 is able to access the AdminClient API. Normally we observed with Event streams APIKEY it is possible to create topic with AdminClient, so there is no need to do the following commands. For other configuration where Access Control policies do not authorize program to create topic dynamically, the commands performed by and admin user will create the needed topic. (the mm2 prefix is the one used by mirror maker, but the name of the topic could be defined in the mirror maker properties)</li>
</ul>
<div class="codehilite"><pre><span></span>ibmcloud es topic-create -n mm2-configs.source.internal -p <span class="m">1</span>  -c cleanup.policy<span class="o">=</span>compact
ibmcloud es topic-create -n mm2-offsets.source.internal -p <span class="m">25</span> -c cleanup.policy<span class="o">=</span>compact
ibmcloud es topic-create -n mm2-status.source.internal -p <span class="m">5</span> -c cleanup.policy<span class="o">=</span>compact
ibmcloud es topic-create -n source.products -p <span class="m">1</span>
ibmcloud es topic-create -n source.heartbeats -p <span class="m">1</span> -c cleanup.policy<span class="o">=</span>compact
ibmcloud es topic-create -n source.checkpoints.internal -p <span class="m">1</span> -c cleanup.policy<span class="o">=</span>compact
</pre></div>

<ul>
<li>In one Terminal window, start the local cluster using <code>docker-compose</code> under the <code>mirror-maker-2/local-cluster</code> folder: <code>docker-compose up &amp;</code>. The data are persisted on the local disk in this folder.</li>
<li>If this is the first time you started the source cluster, you need to create the <code>products</code> topic. Start a Kafka container to access the Kafka tools with the command:</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --network kafkanet strimzi/kafka:latest-kafka-2.4.0 bash
</pre></div>

<p>Then in the bash shell, go to <code>/home/local-cluster</code> folder and execute the script: <code>./createProductsTopic.sh</code>. Verify topic is created with the command: <code>/opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --list</code></p>
<ul>
<li>Send some products data to this topic. For that we use a docker python image. The docker file to build this image is <code>python-kafka/Dockerfile-python</code> so the command to build this image (if you change the image name be sure to use the new name in future command) is: <code>docker build -f Dockerfile-python -t jbcodeforce/python37 .</code></li>
</ul>
<p>Once the image is built, start the python environment with the following commands:</p>
<div class="codehilite"><pre><span></span><span class="nb">source</span> ./setenv.sh
docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --rm -e <span class="nv">KAFKA_BROKERS</span><span class="o">=</span><span class="nv">$KAFKA_SOURCE_BROKERS</span> --network kafkanet jbcodeforce/python37   bash
</pre></div>

<p>In this isolated python container bash shell do the following to send the 5 first products:</p>
<div class="codehilite"><pre><span></span>$ <span class="nb">echo</span> <span class="nv">$KAFKA_BROKERS</span>
kafka1:9092,kafka2:9093,kafka3:9094
$ python SendProductToKafka.py ./data/products.json

<span class="o">[</span>KafkaProducer<span class="o">]</span> - <span class="o">{</span><span class="s1">&#39;bootstrap.servers&#39;</span>: <span class="s1">&#39;kafka1:9092,kafka2:9093,kafka3:9094&#39;</span>, <span class="s1">&#39;group.id&#39;</span>: <span class="s1">&#39;ProductsProducer&#39;</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P01&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Carrots&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P02&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Banana&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">6</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.6, <span class="s1">&#39;content_type&#39;</span>: <span class="m">2</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P03&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Salad&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P04&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Avocado&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">6</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P05&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Tomato&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">2</span><span class="o">}</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
</pre></div>

<ul>
<li>To validate the data are in the source topic we can use the kafka console consumer. Here are the basic commands:</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --network kafkanet strimzi/kafka:latest-kafka-2.4.0 bash
$ <span class="nb">cd</span> bin
$ ./kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic products --from-beginning
</pre></div>

<ul>
<li>Define the event streams cluster properties file for the different Kafka tool commands. Set the password attribute of the <code>jaas.config</code> to match Event Streams APIKEY. The <code>eventstream.properties</code> file looks like:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="na">bootstrap.servers</span><span class="o">=</span><span class="s">broker-3-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-5-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093</span>
<span class="na">security.protocol</span><span class="o">=</span><span class="s">SASL_SSL</span>
<span class="na">ssl.protocol</span><span class="o">=</span><span class="s">TLSv1.2</span>
<span class="na">sasl.mechanism</span><span class="o">=</span><span class="s">PLAIN</span>
<span class="na">sasl.jaas.config</span><span class="o">=</span><span class="s">org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;token&quot; password=....;</span>
</pre></div>

<ul>
<li>Restart the <code>kafka-console-consumer</code> with the bootstrap URL to access to Event Streams and with the replicated topic: <code>source.products</code>. Use the previously created properties file to get authentication properties so the command looks like:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="nb">source</span> /home/setenv.sh
./kafka-console-consumer.sh --bootstrap-server <span class="nv">$KAFKA_TARGET_BROKERS</span> --consumer.config /home/eventstream.properties --topic source.products --from-beginning
</pre></div>

<ul>
<li>Now we are ready to start Mirror Maker 2.0, close to the local cluster, using, yet another docker image:</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --network kafkanet strimzi/kafka:latest-kafka-2.4.0 bash
$ /home/local-cluster/launchMM2.sh
</pre></div>

<p><em>This <code>launchMM2.sh</code> script is updating a template properties file with the values of the environment variables and calls with this updated file: <code>/opt/kafka/bin/connect-mirror-maker.sh mm2.properties</code></em></p>
<p>The trace includes a ton of messages, which displays different Kafka connect consumers and producers, workers and tasks. The logs can be found in the <code>/tmp/logs</code> folder within the docker container. The table includes some of the elements of this configuration:</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Worker clientId=connect-2, groupId=target-mm2</td>
<td>Herder for target cluster topics but reading source topic</td>
</tr>
<tr>
<td>Producer clientId=producer-1</td>
<td>Producer to taget cluster</td>
</tr>
<tr>
<td>Consumer clientId=consumer-target-mm2-1, groupId=target-mm2]</td>
<td>Subscribed to 25 partition(s): mm2-offsets.target.internal-0 to 24</td>
</tr>
<tr>
<td>Consumer clientId=consumer-target-mm2-2, groupId=target-mm2]</td>
<td>Subscribed to 5 partition(s): mm2-status.target.internal-0 to 4</td>
</tr>
<tr>
<td>Consumer clientId=consumer-target-mm2-3, groupId=target-mm2]</td>
<td>Subscribed to partition(s): mm2-configs.target.internal-0</td>
</tr>
<tr>
<td>Worker clientId=connect-2, groupId=target-mm2 . Starting connectors and tasks using config offset 6.</td>
<td>This trace shows mirror maker will start to consume message from the offset 6. A previous run has already committed the offset for this client id. This illustrate a Mirror Maker restarts</td>
</tr>
<tr>
<td>Starting connector MirrorHeartbeatConnector and Starting task MirrorHeartbeatConnector-0</td>
<td></td>
</tr>
<tr>
<td>Starting connector MirrorCheckpointConnector</td>
<td></td>
</tr>
<tr>
<td>Starting connector MirrorSourceConnector</td>
<td></td>
</tr>
</tbody>
</table>
<p>As expected, in the consumer console we can see the 5 product messages arriving to the <code>source.topics</code> after the replication complete.</p>
<div class="codehilite"><pre><span></span><span class="o">{</span><span class="s1">&#39;bootstrap.servers&#39;</span>: <span class="s1">&#39;kafka1:9092,kafka2:9093,kafka3:9094&#39;</span>, <span class="s1">&#39;group.id&#39;</span>: <span class="s1">&#39;ProductsProducer&#39;</span><span class="o">}</span>
  <span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P01&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Carrots&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
  <span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P02&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Banana&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">6</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.6, <span class="s1">&#39;content_type&#39;</span>: <span class="m">2</span><span class="o">}</span>
  <span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P03&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Salad&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
  <span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P04&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Avocado&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">6</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
  <span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P05&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Tomato&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">2</span><span class="o">}</span>
</pre></div>

<h2 id="scenario-2-run-mirror-maker-2-cluster-close-to-target-cluster">Scenario 2: Run Mirror Maker 2 Cluster close to target cluster</h2>
<p>This scenario is similar to the scenario 1 but Mirror Maker 2.0 now, runs within an OpenShift cluster in the same data center as Event Streams cluster, so closer to the target cluster:</p>
<p><img alt="Local to ES" src="../images/mm2-local-to-es.png" /></p>
<p>We have created an Event Streams cluster on Washington DC data center. We have Strimzi operators deployed in Washington data center OpenShift Cluster.</p>
<p>Producers are running locally on the same OpenShift cluster, where vanilla Kafka 2.4 is running, or can run remotely using exposed Kafka brokers Openshift route. (The black rectangles in the figure above represent those producers.)</p>
<p>The goal is to replicate the <code>products</code> topic from the left to the <code>source.products</code> to the right.</p>
<p>What needs to be done:</p>
<ul>
<li>Get a OpenShift cluster in the same data center as Event Streams service: See this <a href="https://cloud.ibm.com/kubernetes/catalog/about?platformType=openshift">product introduction</a>.</li>
<li>If not done yet, create a secret for the API KEY of the Event Streams cluster:
<code>oc create secret generic es-api-secret --from-literal=password=&lt;replace-with-event-streams-apikey&gt;</code></li>
<li>Create a project in OpenShift to deploy Mirror Maker cluster, for example: <code>oc new-project mirror-maker-2-to-es</code>.</li>
<li>At the minimum, to run Mirror Maker 2, we need to deploy the Strimzi Custom Resource Definitions, and the Mirror Maker 2.0 operator. See the detail in the section "" from the <a href="../provisioning/">provisioning note</a>.</li>
<li>As the vanilla Kafka source cluster is using TLS to communicate between clients and brokers, we need to use the k8s secret defined when deploying Kafka which includes the CAroot certificate. This secret is : <code>my-cluster-clients-ca-cert</code>.</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># build a local CA crt file from the secret:</span>
oc extract secret/my-cluster-clients-ca-cert --keys<span class="o">=</span>ca.crt --to<span class="o">=</span>- &gt; ca.crt
<span class="c1"># Verify the certificate:</span>
openssl x509 -in ca.crt -text
<span class="c1"># transform it for java truststore.jks:</span>
keytool -import -trustcacerts -alias root -file ca.crt -keystore truststore.jks -storepass password -noprompt
<span class="c1"># create a secret from file the truststore so it can be mounted as needed</span>
oc create secret generic kafka-truststore --from-file<span class="o">=</span>./truststore.jks
<span class="c1"># Verify the created secret</span>
oc describe secret kafka-truststore
</pre></div>

<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>At this step, we have two options to deploy mirror maker, one using the Mirror Maker Operator and configur it via a yaml file, or use properties file and a special docker image that is deployed to Openshift. As of 3/20/2020 we have found an issue on Strimzi 0.17-rc2 Mirror Maker 2.0 operator, so we are proposing to use the properties approach as <a href="../sc2-mm2/">documented in this separated note</a>.</p>
</div>
<h3 id="deploy-mirror-maker-as-a-custom-image">Deploy Mirror Maker as a custom image</h3>
<p>In this approach, <a href="../sc2-mm2/">documented in a separate note</a>,  we are using properties file to define the Mirror Maker 2.0 configuration, package JMX exporter with it inside a docker image and deploy the image to Openshift.</p>
<h3 id="deploy-with-strimzi-mirror-maker-20-operator">Deploy with Strimzi Mirror Maker 2.0 Operator</h3>
<ul>
<li>Define source and target cluster properties in mirror maker 2.0 <code>kafka-to-es-mm2.yml</code> descriptor file. We strongly recommend to study the schema definition of this <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/2d35bfcd99295bef8ee98de9d8b3c86cb33e5842/install/cluster-operator/048-Crd-kafkamirrormaker2.yaml#L648-L663">custom resource from this page</a>. The <a href="https://github.com/jbcodeforce/kp-data-replication/blob/master/mirror-maker-2/local-cluster/kafka-to-es-mm2.yml">yaml file we used is here</a>.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>connectCluster defined the cluster alias used for Kafka Connect, it must match a cluster in the list at <code>spec.clusters</code>.
The config part can match the Kafka configuration for consumer or producer, except properties starting by ssl, sasl, security, listeners, rest, bootstarp.servers which are declared at the cluster definition level. Also we have some challenges to make the connection to event streams working, as of Strimzi version 0.17 RC2, we need to add an empty <code>tls: {}</code> stanza to get connected. Also below, the declaration is using the previously defined secret for event streams API key.</p>
</div>
<div class="codehilite"><pre><span></span>  <span class="nt">alias</span><span class="p">:</span> <span class="s">&quot;event-streams-wdc-as-target&quot;</span>
    <span class="nt">bootstrapServers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">broker-3...</span>
    <span class="nt">tls</span><span class="p">:</span> <span class="p p-Indicator">{}</span>
    <span class="nt">authentication</span><span class="p">:</span>
      <span class="nt">passwordSecret</span><span class="p">:</span>
          <span class="nt">secretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">es-api-secret</span>  
          <span class="nt">password</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">password</span>
      <span class="nt">username</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">token</span>
      <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">plain</span>
</pre></div>

<ul>
<li>Deploy Mirror maker 2.0 within your project.</li>
</ul>
<div class="codehilite"><pre><span></span>oc apply -f kafka-to-es-mm2.yaml
</pre></div>

<p>This commmand creates a kubernetes deployment as illustrated below, with one pod as the replicas is set to 1. If we need to add parallel processing because of the topics to replicate have multiple partitions, or there are a lot of topics to replicate, then adding pods will help to scale horizontally. The pods are in the same consumer group, so Kafka Brokers will do the partition rebalancing among those new added consumers.</p>
<p><img alt="Mirror maker deployment" src="../images/mm2-deployment.png" /></p>
<h3 id="validate-data-replication">Validate data replication</h3>
<p>To validate the replication works, we will connect a consumer to the <code>source.products</code> topic on Event Streams. So we define a target cluster property file (<code>eventstreams.properties</code>) like:</p>
<div class="codehilite"><pre><span></span><span class="na">security.protocol</span><span class="o">=</span><span class="s">SASL_SSL</span>
<span class="na">ssl.protocol</span><span class="o">=</span><span class="s">TLSv1.2</span>
<span class="na">sasl.mechanism</span><span class="o">=</span><span class="s">PLAIN</span>
<span class="na">sasl.jaas.config</span><span class="o">=</span><span class="s">org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;token&quot; password=&quot;am_...&quot;;</span>
</pre></div>

<ul>
<li>Start the consumer on <code>source.products</code> topic running in Event Streams on the cloud: we use a <code>setenv.sh</code> shell to export the needed environment variables</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home strimzi/kafka:latest-kafka-2.4.0 bash
bash-4.2$ <span class="nb">source</span> /home/setenv.sh
bash-4.2$ ./bin/kafka-console-consumer.sh --bootstrap-server <span class="nv">$KAFKA_TARGET_BROKERS</span> --consumer.config /home/eventstream.properties --topic source.products --from-beginning
</pre></div>

<ul>
<li>Start a producer to send product records to the source Kafka cluster. If you have done the scenario 1, the first product definitions may be already in the target cluster, so we can send a second batch of products using a second data file:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="nb">export</span> <span class="nv">KAFKA_BROKERS</span><span class="o">=</span><span class="s2">&quot;my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443&quot;</span>
<span class="nb">export</span> <span class="nv">KAFKA_CERT</span><span class="o">=</span><span class="s2">&quot;/home/ca.crt&quot;</span>
docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --rm -e <span class="nv">KAFKA_CERT</span><span class="o">=</span><span class="nv">$KAFKA_CERT</span> -e <span class="nv">KAFKA_BROKERS</span><span class="o">=</span><span class="nv">$KAFKA_BROKERS</span> strimzi/kafka:latest-kafka-2.4.0 bash -c <span class="s2">&quot;/opt/kafka/bin/kafka-console-producer.sh --broker-list </span><span class="nv">$KAFKA_BROKERS</span><span class="s2"> --producer.config /home/kafka-strimzi.properties --topic products&quot;</span>
</pre></div>

<p>As an alternate solution you can run the producer as a pod inside of the source cluster then send the product one by one using the console:</p>
<div class="codehilite"><pre><span></span>oc run kafka-producer -ti --image<span class="o">=</span>strimzi/kafka:latest-kafka-2.4.0  --rm<span class="o">=</span><span class="nb">true</span> --restart<span class="o">=</span>Never -- bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9092 --topic products
If you don t see a <span class="nb">command</span> prompt, try pressing enter.

&gt;<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P01&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Carrots&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
&gt;<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P02&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Banana&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">6</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.6, <span class="s1">&#39;content_type&#39;</span>: <span class="m">2</span><span class="o">}</span>
&gt;<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P03&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Salad&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
&gt;<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P04&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Avocado&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">6</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
&gt;<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P05&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Tomato&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">2</span><span class="o">}</span>
</pre></div>

<p><em>There is other solution, like using an Kafka HTTP brigde and use curl post to send the records</em></p>
<ul>
<li>To validate the source <code>products</code> topic has records, start a consumer as pod on Openshift within the source Kafka cluster using the Strimzi/kafka image.</li>
</ul>
<div class="codehilite"><pre><span></span>oc run kafka-consumer -ti --image<span class="o">=</span>strimzi/kafka:latest-kafka-2.4.0 --rm<span class="o">=</span><span class="nb">true</span> --restart<span class="o">=</span>Never -- bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic products --from-beginning
</pre></div>

<ul>
<li>In the terminal where kafka consumer runs to get message from <code>source.products</code> you should see the data replicated.</li>
</ul>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href=".." title="Introduction" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Introduction
              </span>
            </div>
          </a>
        
        
          <a href="../es-to-local/" title="Replication from Event Streams to local" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Replication from Event Streams to local
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.b806dc00.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>